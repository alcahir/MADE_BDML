{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c6042b5-a3ab-4ca5-9eb5-f16e78ef3ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  jigsaw-toxic-comment-classification-challenge.zip\n",
      "  inflating: sample_submission.csv.zip  \n",
      "  inflating: test.csv.zip            \n",
      "  inflating: test_labels.csv.zip     \n",
      "  inflating: train.csv.zip           \n"
     ]
    }
   ],
   "source": [
    "!unzip jigsaw-toxic-comment-classification-challenge.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a82d22-f6fd-41f1-937e-556445e89be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  train.csv.zip\n",
      "  inflating: train.csv               \n"
     ]
    }
   ],
   "source": [
    "!unzip train.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eab0e7a-11e1-4632-a00e-06aa50ddb673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[1]\") \\\n",
    "        .appName(\"HashingTF\") \\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94230a6b-bc94-4597-8a67-7d3c7b201a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- comment_text: string (nullable = true)\n",
      " |-- toxic: integer (nullable = true)\n",
      " |-- severe_toxic: integer (nullable = true)\n",
      " |-- obscene: integer (nullable = true)\n",
      " |-- threat: integer (nullable = true)\n",
      " |-- insult: integer (nullable = true)\n",
      " |-- identity_hate: integer (nullable = true)\n",
      "\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "|0000997932d777bf|Explanation\\nWhy ...|    0|           0|      0|     0|     0|            0|\n",
      "|000103f0d9cfb60f|D'aww! He matches...|    0|           0|      0|     0|     0|            0|\n",
      "|000113f07ec002fd|Hey man, I'm real...|    0|           0|      0|     0|     0|            0|\n",
      "|0001b41b1c6bb37e|\"\\nMore\\nI can't ...|    0|           0|      0|     0|     0|            0|\n",
      "|0001d958c54c6e35|You, sir, are my ...|    0|           0|      0|     0|     0|            0|\n",
      "|00025465d4725e87|\"\\n\\nCongratulati...|    0|           0|      0|     0|     0|            0|\n",
      "|0002bcb3da6cb337|COCKSUCKER BEFORE...|    1|           1|      1|     0|     1|            0|\n",
      "|00031b1e95af7921|Your vandalism to...|    0|           0|      0|     0|     0|            0|\n",
      "|00037261f536c51d|Sorry if the word...|    0|           0|      0|     0|     0|            0|\n",
      "|00040093b2687caa|alignment on this...|    0|           0|      0|     0|     0|            0|\n",
      "|0005300084f90edc|\"\\nFair use ratio...|    0|           0|      0|     0|     0|            0|\n",
      "|00054a5e18b50dd4|bbq \\n\\nbe a man ...|    0|           0|      0|     0|     0|            0|\n",
      "|0005c987bdfc9d4b|Hey... what is it...|    1|           0|      0|     0|     0|            0|\n",
      "|0006f16e4e9f292e|Before you start ...|    0|           0|      0|     0|     0|            0|\n",
      "|00070ef96486d6f9|Oh, and the girl ...|    0|           0|      0|     0|     0|            0|\n",
      "|00078f8ce7eb276d|\"\\n\\nJuelz Santan...|    0|           0|      0|     0|     0|            0|\n",
      "|0007e25b2121310b|Bye! \\n\\nDon't lo...|    1|           0|      0|     0|     0|            0|\n",
      "|000897889268bc93|REDIRECT Talk:Voy...|    0|           0|      0|     0|     0|            0|\n",
      "|0009801bd85e5806|The Mitsurugi poi...|    0|           0|      0|     0|     0|            0|\n",
      "|0009eaea3325de8c|Don't mean to bot...|    0|           0|      0|     0|     0|            0|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .option(\"delimiter\", ',') \\\n",
    "    .option(\"multiLine\", True) \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .csv(\"train.csv\")\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6839beb6-ec44-442b-ad0e-8a5ea9b29f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover, Word2Vec\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3cd7e0a-1e83-4edd-9b16-81a6734b3b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "clean_text_udf = udf(lambda z: clean_text(z),StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a382a828-e301-4305-bcf8-7f34f832c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def htf_transforms(num_features):\n",
    "    tokenizer = Tokenizer(inputCol=\"clear_text\", outputCol=\"words\")\n",
    "    stop_words_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"clear_words\")\n",
    "    tf  = HashingTF(inputCol=\"clear_words\", outputCol=\"tf_features\", numFeatures=num_features)\n",
    "    idf = IDF(inputCol=\"tf_features\", outputCol=\"idf_features\")\n",
    "    pipeline = Pipeline(stages=[tokenizer, stop_words_remover, tf, idf])\n",
    "    model = pipeline.fit(train_df)\n",
    "    train_data = model.transform(train_df)\n",
    "    val_data = model.transform(val_df)\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10243cc-ed5a-4af2-9061-8b2dd478a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "df = df.withColumn('clear_text', clean_text_udf(col(\"comment_text\")))\n",
    "train_df, val_df = df.randomSplit(weights=[0.8, 0.2], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a400dada-cd66-47c3-afa6-1e94641e5db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features=50\n",
      "Training Dataset Count: 127378\n",
      "Test Dataset Count: 32193\n",
      "Label -->> toxic\n",
      "areaUnderROC 0.5093374660598615\n",
      "Label -->> severe_toxic\n",
      "areaUnderROC 0.5251847985885126\n",
      "Label -->> obscene\n",
      "areaUnderROC 0.5110121518727708\n",
      "Label -->> threat\n",
      "areaUnderROC 0.4999532637482474\n",
      "Label -->> insult\n",
      "areaUnderROC 0.5088514084948993\n",
      "Label -->> identity_hate\n",
      "areaUnderROC 0.5033000011015185\n",
      "Num features=550\n",
      "Training Dataset Count: 127378\n",
      "Test Dataset Count: 32193\n",
      "Label -->> toxic\n",
      "areaUnderROC 0.6126581294577902\n",
      "Label -->> severe_toxic\n",
      "areaUnderROC 0.5959163002240352\n",
      "Label -->> obscene\n",
      "areaUnderROC 0.645615291981721\n",
      "Label -->> threat\n",
      "areaUnderROC 0.5554525627044711\n",
      "Label -->> insult\n",
      "areaUnderROC 0.5767570399841414\n",
      "Label -->> identity_hate\n",
      "areaUnderROC 0.5212697394230924\n",
      "Num features=1050\n",
      "Training Dataset Count: 127378\n",
      "Test Dataset Count: 32193\n",
      "Label -->> toxic\n",
      "areaUnderROC 0.6695705913988911\n",
      "Label -->> severe_toxic\n",
      "areaUnderROC 0.6150367816888936\n",
      "Label -->> obscene\n",
      "areaUnderROC 0.7177144015445053\n",
      "Label -->> threat\n",
      "areaUnderROC 0.6162252687334475\n",
      "Label -->> insult\n",
      "areaUnderROC 0.6334815360110292\n",
      "Label -->> identity_hate\n",
      "areaUnderROC 0.5362529857505874\n",
      "Num features=1550\n",
      "Training Dataset Count: 127378\n",
      "Test Dataset Count: 32193\n",
      "Label -->> toxic\n",
      "areaUnderROC 0.7021991556573924\n",
      "Label -->> severe_toxic\n",
      "areaUnderROC 0.6383366768392953\n",
      "Label -->> obscene\n",
      "areaUnderROC 0.7381337082189106\n",
      "Label -->> threat\n",
      "areaUnderROC 0.6303006698862752\n",
      "Label -->> insult\n",
      "areaUnderROC 0.6494336136144712\n",
      "Label -->> identity_hate\n",
      "areaUnderROC 0.5457454272154714\n"
     ]
    }
   ],
   "source": [
    "for num_features in range(50, 2001, 500):\n",
    "    train_data, val_data = htf_transforms(num_features)\n",
    "    print(f\"Num features={num_features}\")\n",
    "    print(\"Training Dataset Count: \" + str(train_data.count()))\n",
    "    print(\"Test Dataset Count: \" + str(val_data.count()))\n",
    "    for label in labels:\n",
    "        classifier = LogisticRegression(featuresCol='idf_features', labelCol=label).fit(train_data)\n",
    "        preds = classifier.transform(val_data).select(col(label).alias(\"label\"), \"prediction\")\n",
    "        metrics = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', metricName='areaUnderROC')\n",
    "        print(f\"Label -->> {label}\")\n",
    "        print(\"areaUnderROC\", metrics.evaluate(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f63125dc-4082-47f2-9197-bfa65896a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_transforms(window_size):\n",
    "    tokenizer = Tokenizer(inputCol=\"clear_text\", outputCol=\"words\")\n",
    "    stop_words_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"clear_words\")\n",
    "    word2Vec = Word2Vec(vectorSize=50, seed=42, inputCol=\"clear_words\", outputCol=\"features\", windowSize=window_size)\n",
    "    pipeline = Pipeline(stages=[tokenizer, stop_words_remover, word2Vec])\n",
    "    model = pipeline.fit(train_df)\n",
    "    train_data = model.transform(train_df)\n",
    "    val_data = model.transform(val_df)\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "63bfaa2e-5ff3-47ee-b709-b509c1580d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 127378\n",
      "Test Dataset Count: 32193 \n",
      "\n",
      "Window size=5\n",
      "Label -->> toxic\n",
      "areaUnderROC 0.7722270705097234\n",
      "Label -->> severe_toxic\n",
      "areaUnderROC 0.5985874819511582\n",
      "Label -->> obscene\n",
      "areaUnderROC 0.7676274816968421\n",
      "Label -->> threat\n",
      "areaUnderROC 0.5304097211403646\n",
      "Label -->> insult\n",
      "areaUnderROC 0.7021400316573909\n",
      "Label -->> identity_hate\n",
      "areaUnderROC 0.5516281184623819\n",
      "\n",
      "\n",
      "Window size=10\n",
      "Label -->> toxic\n",
      "areaUnderROC 0.7819299002501171\n",
      "Label -->> severe_toxic\n",
      "areaUnderROC 0.5970792499927383\n",
      "Label -->> obscene\n",
      "areaUnderROC 0.7721374949170335\n",
      "Label -->> threat\n",
      "areaUnderROC 0.525307680324038\n",
      "Label -->> insult\n",
      "areaUnderROC 0.7037501158015008\n",
      "Label -->> identity_hate\n",
      "areaUnderROC 0.55161244300701\n",
      "\n",
      "\n",
      "Window size=15\n",
      "Label -->> toxic\n",
      "areaUnderROC 0.7780158751262689\n",
      "Label -->> severe_toxic\n",
      "areaUnderROC 0.5999701567496811\n",
      "Label -->> obscene\n",
      "areaUnderROC 0.7755939401634073\n",
      "Label -->> threat\n",
      "areaUnderROC 0.5151503349431376\n",
      "Label -->> insult\n",
      "areaUnderROC 0.705412377860546\n",
      "Label -->> identity_hate\n",
      "areaUnderROC 0.5482654155393756\n",
      "\n",
      "\n",
      "Window size=20\n",
      "Label -->> toxic\n",
      "areaUnderROC 0.7741285940640253\n",
      "Label -->> severe_toxic\n",
      "areaUnderROC 0.5985403980161969\n",
      "Label -->> obscene\n",
      "areaUnderROC 0.7728907032317814\n",
      "Label -->> threat\n",
      "areaUnderROC 0.5049774108116528\n",
      "Label -->> insult\n",
      "areaUnderROC 0.7052814449636557\n",
      "Label -->> identity_hate\n",
      "areaUnderROC 0.5482967664501195\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Dataset Count: \" + str(train_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(val_data.count()), \"\\n\")\n",
    "for window_size in range(5, 21, 5):\n",
    "    train_data, val_data = w2v_transforms(window_size)\n",
    "    print(f\"Window size={window_size}\")\n",
    "    for label in labels:\n",
    "        classifier = LogisticRegression(featuresCol='features', labelCol=label).fit(train_data)\n",
    "        preds = classifier.transform(val_data).select(col(label).alias(\"label\"), \"prediction\")\n",
    "        metrics = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', metricName='areaUnderROC')\n",
    "        print(f\"Label -->> {label}\")\n",
    "        print(\"areaUnderROC\", metrics.evaluate(preds))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3456bd7c-6855-427f-a6f1-2f3be0ceeff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
